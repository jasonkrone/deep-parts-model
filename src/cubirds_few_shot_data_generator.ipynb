{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from tf_classification.preprocessing.decode_example import decode_serialized_example\n",
    "import numpy as np \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewshotBirdsDataGenerator(object):\n",
    "    \n",
    "        def __init__(self, batch_size=16, episode_length=10, image_dim=(84, 84, 3)):\n",
    "            self.data_dir = '/dvmm-filer2/users/jason/tensorflow_datasets/cub/with_600_val_split/'\n",
    "            \n",
    "            self.split_dir = ''\n",
    "            self.parts     = '' \n",
    "            \n",
    "            \n",
    "            self.handle_placeholder = tf.placeholder(tf.string, shape=[])\n",
    "            self.batch_size = batch_size\n",
    "            self.episode_length = episode_length\n",
    "            self.image_dim = image_dim\n",
    "            self.num_classes = 200\n",
    "            self.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdsDataGenerator(object):\n",
    "    \"\"\"\n",
    "    this class generates supervised batches\n",
    "    you must use alternate data generator for few-shot batches\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=16, episode_length=10, image_dim=(84, 84, 3)):\n",
    "        self.data_dir = '/dvmm-filer2/users/jason/tensorflow_datasets/cub/with_600_val_split/'\n",
    "        self.handle_placeholder = tf.placeholder(tf.string, shape=[])\n",
    "        self.batch_size = batch_size\n",
    "        self.episode_length = episode_length\n",
    "        self.image_dim = image_dim\n",
    "        self.num_classes = 200\n",
    "        self.load_data()\n",
    "\n",
    "    def cubirds_sample_episode_batch(self, sess, mode='train'):\n",
    "        \"\"\"\n",
    "        Samples a batch of data from cubirds dataset of the shape: batch-size x episode-length x image_dim\n",
    "\n",
    "        sess: session to run when collecting batches\n",
    "        mode: specifies the data_set split to use (train, val, or test)\n",
    "        \"\"\"\n",
    "        handle = None\n",
    "        if mode == 'train':\n",
    "            handle = sess.run(self.train_handle)\n",
    "        elif mode == 'val':\n",
    "            handle = sess.run(self.val_handle)\n",
    "        elif mode == 'test':\n",
    "            handle = sess.run(self.test_handle)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be one of: (train, val, or test)\")\n",
    "\n",
    "        h, w, c = self.image_dim\n",
    "        x_shape = [self.batch_size, self.episode_length, h, w, c]\n",
    "        episodes_x = np.zeros(shape=x_shape)\n",
    "        # bodys\n",
    "        episodes_body = np.zeros(shape=x_shape)\n",
    "        # heads\n",
    "        episodes_head = np.zeros(shape=x_shape)\n",
    "        # we need 1 y per part\n",
    "        y_shape = [self.batch_size, self.episode_length*2]\n",
    "        episodes_y = np.zeros(shape=y_shape)\n",
    "\n",
    "        feed_dict = {self.handle_placeholder : handle}\n",
    "        for i in xrange(self.batch_size):\n",
    "            ep_x, ep_body, ep_head, ep_y = sess.run(self.next_batch, feed_dict=feed_dict)\n",
    "            episodes_x[i] = ep_x\n",
    "            episodes_body[i] = ep_body\n",
    "            episodes_head[i] = ep_head\n",
    "            episodes_y[i] = np.concatenate([ep_y, ep_y], axis=0)\n",
    "        return episodes_x, episodes_body, episodes_head, episodes_y\n",
    "\n",
    "    def load_data(self):\n",
    "        train_path = os.path.join(self.data_dir, 'train*')\n",
    "        train_data = self.batched_dataset_from_records(train_path, mode='train', batch_size=self.episode_length)\n",
    "        train_iter = train_data.make_one_shot_iterator()\n",
    "\n",
    "        val_path = os.path.join(self.data_dir, 'val*')\n",
    "        val_data = self.batched_dataset_from_records(val_path, mode='train', batch_size=self.episode_length)\n",
    "        val_iter = val_data.make_one_shot_iterator()\n",
    "\n",
    "        test_path = os.path.join(self.data_dir, 'test*')\n",
    "        test_data = self.batched_dataset_from_records(test_path, mode='test', batch_size=self.episode_length)\n",
    "        test_iter = test_data.make_one_shot_iterator()\n",
    "\n",
    "        # to switch between train and test, set the handle_placeholder value to train_handle or test_handle\n",
    "        iterator = tf.data.Iterator.from_string_handle(self.handle_placeholder, train_data.output_types, train_data.output_shapes)\n",
    "        self.next_batch = iterator.get_next()\n",
    "        self.train_handle = train_iter.string_handle()\n",
    "        self.val_handle = val_iter.string_handle()\n",
    "        self.test_handle = test_iter.string_handle()\n",
    "\n",
    "    def batched_dataset_from_records(self, records_path, mode='train', batch_size=32):\n",
    "        files = tf.data.Dataset.list_files(records_path)\n",
    "        # parallelize creation reading of records\n",
    "        #files.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, cycle_length=4))\n",
    "        dataset = files.interleave(tf.data.TFRecordDataset, cycle_length=4)\n",
    "        # suffle dataset so batches don't contain single class etc, then repeat for epochs\n",
    "        #dataset = tf.contrib.data.shuffle_and_repeat(dataset)\n",
    "        dataset = dataset.shuffle(buffer_size=6000) # next item randomly chosen from buffer of buffer_size\n",
    "        dataset = dataset.repeat()\n",
    "        # parse serialized examples in parallel\n",
    "        dataset = dataset.map(lambda ex : self.parser(ex, mode), num_parallel_calls=8)\n",
    "        # create batches\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        # allow generation of data and consumption of data to occur at the same time\n",
    "        dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "        return dataset\n",
    "\n",
    "    def parser(self, serialized_example, mode='train'):\n",
    "        features_to_fetch = [\n",
    "            ('image/encoded', 'image'), ('image/class/label', 'label'),\n",
    "            ('image/height', 'height'), ('image/width', 'width'),\n",
    "            ('image/channels', 'channels'), ('image/object/parts/x', 'part_x'),\n",
    "            ('image/object/parts/y', 'part_y'), ('image/object/parts/v', 'part_v'),\n",
    "            ('image/object/bbox/xmin', 'xmin'), ('image/object/bbox/xmax', 'xmax'),\n",
    "            ('image/object/bbox/ymin', 'ymin'), ('image/object/bbox/ymax', 'ymax')\n",
    "        ]\n",
    "        # extract tensor values from serialized example\n",
    "        example_dict = decode_serialized_example(serialized_example, features_to_fetch)\n",
    "        label = example_dict['label']\n",
    "        image = example_dict['image']\n",
    "        part_x, part_y, part_v = example_dict['part_x'], example_dict['part_y'], example_dict['part_v']\n",
    "        xmin, xmax, ymin, ymax = example_dict['xmin'], example_dict['xmax'], example_dict['ymin'], example_dict['ymax']\n",
    "\n",
    "        # set image size\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "        height, width, channels = example_dict['height'], example_dict['width'], example_dict['channels']\n",
    "        height, width, channels = tf.cast(height, tf.int32), tf.cast(width, tf.int32), tf.cast(channels, tf.int32)\n",
    "        image = tf.reshape(image, ([height, width, channels]))\n",
    "        new_height, new_width, new_channels = self.image_dim\n",
    "        \n",
    "        # extract parts\n",
    "        part_x, part_y = tf.cast(part_x, tf.float32), tf.cast(part_y, tf.float32)\n",
    "        part_x, part_y = tf.reshape(part_x, shape=[15]), tf.reshape(part_y, shape=[15])\n",
    "        breast_x, breast_y = part_x[3], part_y[3]\n",
    "        crown_x, crown_y = part_x[4], part_y[4]\n",
    "        nape_x, nape_y = part_x[9], part_y[9]\n",
    "        tail_x, tail_y = part_x[13], part_y[13]\n",
    "        leg_x, leg_y = part_x[7], part_y[7]\n",
    "        beak_x, beak_y = part_x[1], part_y[1]\n",
    "        \n",
    "        # get crop for body\n",
    "        bxmin, bxmax = tf.minimum(tail_x, beak_x), tf.maximum(tail_x, beak_x)\n",
    "        bymin, bymax = tf.minimum(leg_y, nape_y), tf.maximum(leg_y, nape_y)\n",
    "        boxes = tf.expand_dims(tf.stack([bymin, bxmin, bymax, bxmax], axis=0), 0)\n",
    "        box_ind = tf.constant([0])\n",
    "        body_crop = tf.image.crop_and_resize(tf.expand_dims(image, 0), boxes, box_ind, [new_height, new_width], method='bilinear', extrapolation_value=0, name=None)        \n",
    "        body_crop = tf.squeeze(body_crop, [0])\n",
    "        \n",
    "        # get crop for head\n",
    "        x_len = tf.abs(beak_x - nape_x)\n",
    "        y_len = tf.abs(crown_x - nape_x)\n",
    "        bymin, bymax = tf.minimum(nape_y, crown_y), tf.maximum(nape_y, crown_y) + y_len\n",
    "        bxmin, bxmax = crown_x - x_len, crown_x + x_len\n",
    "        boxes = tf.expand_dims(tf.stack([bymin, bxmin, bymax, bxmax], axis=0), 0)\n",
    "        head_crop = tf.image.crop_and_resize(tf.expand_dims(image, 0), boxes, box_ind, [new_height, new_width], method='bilinear', extrapolation_value=0, name=None)        \n",
    "        head_crop = tf.squeeze(head_crop, [0])\n",
    "        \n",
    "        if mode == 'train':\n",
    "            # resize the image to 256xS where S is max(largest-image-side, 244)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            clipped_height, clipped_width = tf.maximum(height, [244]), tf.maximum(width, [244])\n",
    "            true_fn = lambda : tf.image.resize_bilinear(image, [clipped_height[0], 256], align_corners=False)\n",
    "            false_fn = lambda : tf.image.resize_bilinear(image, [256, clipped_width[0]], align_corners=False)\n",
    "            image = tf.cond(tf.greater(height, width), true_fn, false_fn)\n",
    "            # TODO: get rid of this\n",
    "            image = tf.image.resize_bilinear(image, [new_height, new_width], align_corners=False)\n",
    "            # TODO: ^\n",
    "            image = tf.squeeze(image, [0])\n",
    "            # preprocess with random crops and horizontal flipping\n",
    "            image = tf.random_crop(image, size=[new_height, new_width, new_channels])\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=0.875)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            image = tf.image.resize_bilinear(image, [new_height, new_width])\n",
    "            image = tf.squeeze(image, [0])\n",
    "        return image, body_crop, head_crop, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('parts for id 1', [None, None, None, None, None, None, None, None, None, None, None, None, None, None, [215.0, 194.0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_val_test_splits = {\\n    'train' : '/home/jason/deep-parts-model/src/cub_fewshot/splits/train_split_few_shot.txt',\\n    'test'  : '/home/jason/deep-parts-model/src/cub_fewshot/splits/test_split_few_shot.txt',\\n    'val'   : '/home/jason/deep-parts-model/src/cub_fewshot/splits/val_split_few_shot.txt'\\n}\\n# readlines from each file\\nfor split, split_path in train_val_test_splits.items():\\n    train_val_test_splits[split] = open(split_path, 'r').readlines()\\n# for each split for each example\\nfor split, lines in train_val_test_splits.items():\\n    new_csv_lines = []\\n    # read lines\\n    for l in lines:\\n        l = l.strip()\\n        s = l.split(' ')\\n        img_path, label = s\\n        img_id = path_to_id_dict[img_path]\\n        bbox = id_to_bbox_dict[img_id]\\n        parts = id_to_parts_dict[img_id]\\n        parts = np.array(parts) # 15 x 2\\n        # put parts togeather in order part1, part2, part3, part4, ..., part15\\n        parts = np.concatenate(parts, axis=0)\\n        bbox_lines.append(bbox)\\n        parts_lines.append(parts)\\n        full_line = [img_path, label] + bbox + parts.tolist()\\n        new_csv_lines.append(full_line)\\n    with open(split+'img_path_label_bbox_parts_split.txt', 'w') as csv_file:\\n        writer = csv.writer(csv_file, delimiter=' ')\\n        for new_line in new_csv_lines:\\n            writer.writerow(new_line)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_id_dict = {}\n",
    "prefix = '/dvmm-filer2/users/jason/datasets/CUB_200_2011/images/'\n",
    "with open('/dvmm-filer2/users/jason/datasets/CUB_200_2011/images.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    split = line.split(' ')\n",
    "    img_id, img_path = split\n",
    "    img_path = prefix + img_path\n",
    "    path_to_id_dict[img_path] = int(img_id)\n",
    "\n",
    "\n",
    "id_to_bbox_dict = {}\n",
    "# read bounding_boxes and create a dict that maps image_id -> bbox\n",
    "with open('/dvmm-filer2/users/jason/datasets/CUB_200_2011/bounding_boxes.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    split = line.split(' ')\n",
    "    img_id, x, y, width, height = split\n",
    "    id_to_bbox_dict[int(img_id)] = [float(x), float(y), float(width), float(height)]\n",
    "\n",
    "id_to_parts_dict = {}\n",
    "with open('/dvmm-filer2/users/jason/datasets/CUB_200_2011/parts/part_locs.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    split = line.split(' ')\n",
    "    img_id, part_id, x, y, visible = split\n",
    "    if img_id not in id_to_parts_dict:\n",
    "        id_to_parts_dict[int(img_id)] = [None] * 15\n",
    "    id_to_parts_dict[int(img_id)][int(part_id)-1] = [float(x), float(y)]\n",
    "print('parts for id 1', id_to_parts_dict[1])\n",
    "'''\n",
    "train_val_test_splits = {\n",
    "    'train' : '/home/jason/deep-parts-model/src/cub_fewshot/splits/train_split_few_shot.txt',\n",
    "    'test'  : '/home/jason/deep-parts-model/src/cub_fewshot/splits/test_split_few_shot.txt',\n",
    "    'val'   : '/home/jason/deep-parts-model/src/cub_fewshot/splits/val_split_few_shot.txt'\n",
    "}\n",
    "# readlines from each file\n",
    "for split, split_path in train_val_test_splits.items():\n",
    "    train_val_test_splits[split] = open(split_path, 'r').readlines()\n",
    "# for each split for each example\n",
    "for split, lines in train_val_test_splits.items():\n",
    "    new_csv_lines = []\n",
    "    # read lines\n",
    "    for l in lines:\n",
    "        l = l.strip()\n",
    "        s = l.split(' ')\n",
    "        img_path, label = s\n",
    "        img_id = path_to_id_dict[img_path]\n",
    "        bbox = id_to_bbox_dict[img_id]\n",
    "        parts = id_to_parts_dict[img_id]\n",
    "        parts = np.array(parts) # 15 x 2\n",
    "        # put parts togeather in order part1, part2, part3, part4, ..., part15\n",
    "        parts = np.concatenate(parts, axis=0)\n",
    "        bbox_lines.append(bbox)\n",
    "        parts_lines.append(parts)\n",
    "        full_line = [img_path, label] + bbox + parts.tolist()\n",
    "        new_csv_lines.append(full_line)\n",
    "    with open(split+'img_path_label_bbox_parts_split.txt', 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=' ')\n",
    "        for new_line in new_csv_lines:\n",
    "            writer.writerow(new_line)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
