{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from scipy.misc import imread,imresize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cub_fewshot.image_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewshotBirdsDataGenerator(object):\n",
    "\n",
    "        def __init__(self, batch_size=100, episode_length=10, episode_width=5, image_dim=(244, 244, 3)):\n",
    "            self.splits = {\n",
    "                'train' : '/home/jason/deep-parts-model/src/cub_fewshot/splits/train_img_path_label_size_bbox_parts_split.txt',\n",
    "                'test'  : '/home/jason/deep-parts-model/src/cub_fewshot/splits/test_img_path_label_size_bbox_parts_split.txt',\n",
    "                'val'   : '/home/jason/deep-parts-model/src/cub_fewshot/splits/val_img_path_label_size_bbox_parts_split.txt'\n",
    "            }\n",
    "            self.batch_size = batch_size\n",
    "            self.episode_length = episode_length\n",
    "            self.episode_width = episode_width\n",
    "            self.image_dim = image_dim\n",
    "            self.num_classes = 200\n",
    "            self._cache = {}\n",
    "            self._load_data()\n",
    "\n",
    "        def _load_data(self):\n",
    "            self.train_data = self._data_dict_for_split(self.splits['train'])\n",
    "            print('finished train')\n",
    "            self.test_data  = self._data_dict_for_split(self.splits['test'])\n",
    "            print('finished test')\n",
    "            self.val_data   = self._data_dict_for_split(self.splits['val'])\n",
    "            print('finished val')\n",
    "\n",
    "        def sample_episode_batch(self, data):\n",
    "            \"\"\"Generates a random batch for training or validation.\n",
    "\n",
    "            Structures each element of the batch as an 'episode'.\n",
    "            Each episode contains episode_length examples and\n",
    "            episode_width distinct labels.\n",
    "\n",
    "            Args:\n",
    "              data: A dictionary mapping label to list of examples.\n",
    "              episode_length: Number of examples in each episode.\n",
    "              episode_width: Distinct number of labels in each episode.\n",
    "              batch_size: Batch size (number of episodes).\n",
    "\n",
    "            Returns:\n",
    "              A tuple (x, y) where x is a list of batches of examples\n",
    "              with size episode_length and y is a list of batches of labels.\n",
    "            \"\"\"\n",
    "            episodes_x = [[] for _ in xrange(self.episode_length)]\n",
    "            episodes_y = [[] for _ in xrange(self.episode_length)]\n",
    "            assert len(data) >= self.episode_width\n",
    "            keys = data.keys()\n",
    "            for b in xrange(self.batch_size):\n",
    "                episode_labels = random.sample(keys, self.episode_width)\n",
    "                remainder = self.episode_length % self.episode_width\n",
    "                remainders = [0] * (self.episode_width - remainder) + [1] * remainder\n",
    "                episode_x = [\n",
    "                  random.sample(data[lab],\n",
    "                                r + (self.episode_length - remainder) // self.episode_width)\n",
    "                  for lab, r in zip(episode_labels, remainders)]\n",
    "                episode = sum([[(x, i, ii) for ii, x in enumerate(xx)]\n",
    "                             for i, xx in enumerate(episode_x)], [])\n",
    "                random.shuffle(episode)\n",
    "                # Arrange episode so that each distinct label is seen before moving to\n",
    "                # 2nd showing\n",
    "                episode.sort(key=lambda elem: elem[2])\n",
    "                assert len(episode) == self.episode_length\n",
    "                for i in xrange(self.episode_length):\n",
    "                    episodes_x[i].append(episode[i][0])\n",
    "                    episodes_y[i].append(episode[i][1] + b * self.episode_width)\n",
    "            episodes_x = self._get_examples_for_image_configs(episodes_x) \n",
    "            episodes_y = [np.array(yy).astype('int32') for yy in episodes_y]\n",
    "            return (episodes_x, episodes_y)\n",
    "\n",
    "        def _data_dict_for_split(self, split, mode='test'):\n",
    "            label_to_examples_dict = {}\n",
    "            with open(split, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                # get x, y, bbox, and parts from line\n",
    "                line = line.strip()\n",
    "                line = line.split(' ')\n",
    "                image_path, y, size, bbox, parts = line[0], line[1], line[2:4], line[4:8], line[8:]\n",
    "                size = [int(s) for s in size]\n",
    "                y, bbox, parts = int(y), [float(b) for b in bbox], [float(p) for p in parts]\n",
    "                parts_x, parts_y = parts[0::2], parts[1::2]\n",
    "                if y not in label_to_examples_dict:\n",
    "                    label_to_examples_dict[y] = []\n",
    "                # example is going to be x, p1, p2\n",
    "                # instead of storing this store args\n",
    "                label_to_examples_dict[y].append((image_path, size, bbox, parts_x, parts_y, mode))\n",
    "            return label_to_examples_dict\n",
    "\n",
    "        def _get_examples_for_image_configs(self, configs):\n",
    "            '''\n",
    "            parses the configs of dim: self.batch_size X self.episode_length X 1\n",
    "            and returns a np.array of image_and_parts of dim: self.batch_size X 3 X self.episode_length X self.image_dim\n",
    "            '''\n",
    "            H, W, C = self.image_dim\n",
    "            examples = [[None] * self.batch_size] * self.episode_length\n",
    "            for i, config_batch in enumerate(configs):\n",
    "                for j, c in enumerate(config_batch):\n",
    "                    image_path, size, bbox, parts_x, parts_y, mode = c\n",
    "                    if image_path in self._cache:\n",
    "                        examples[i][j] = self._cache[image_path]\n",
    "                    else:\n",
    "                        image_and_parts = self._parser(image_path, size, bbox, parts_x, parts_y, mode)\n",
    "                        examples[i][j] = image_and_parts\n",
    "                        self._cache[image_path] = image_and_parts\n",
    "            return [np.array(xx).astype('uint8') for xx in examples]\n",
    "\n",
    "        def _parser(self, image_path, size, bbox, parts_x, parts_y, mode='test'):\n",
    "            # decode the image\n",
    "            image = imread(image_path) # imread(image_path)\n",
    "            # get height and width of image to normalize the bounding box and part locations\n",
    "            height, width = size\n",
    "            # normalize bbox\n",
    "            x, y, w, h = bbox\n",
    "            # extract parts\n",
    "            breast_x, breast_y = int(parts_x[3]), int(parts_y[3])\n",
    "            crown_x, crown_y = int(parts_x[4]), int(parts_y[4])\n",
    "            nape_x, nape_y = int(parts_x[9]), int(parts_y[9])\n",
    "            tail_x, tail_y = int(parts_x[13]), int(parts_y[13])\n",
    "            leg_x, leg_y = int(parts_x[7]), int(parts_y[7])\n",
    "            beak_x, beak_y = int(parts_x[1]), int(parts_y[1])\n",
    "\n",
    "            new_height, new_width, new_channels = self.image_dim\n",
    "            # get crop for body\n",
    "            bxmin, bxmax = min(tail_x, beak_x), max(tail_x, beak_x)\n",
    "            bymin, bymax = min(leg_y, nape_y, breast_y), max(leg_y, nape_y, breast_y)\n",
    "            bymin, bymax, bxmin, bxmax = int(bymin), int(bymax), int(bxmin), int(bxmax)\n",
    "            try:\n",
    "                body_crop = image[bymin:bymax, bxmin:bxmax, :]\n",
    "                body_crop = imresize(body_crop, size=(new_height, new_width))\n",
    "            except:\n",
    "                h_size = int((0.75 * h) / 2)\n",
    "                w_size = int((0.75 * w) / 2)\n",
    "                print('image shape:', image.shape)\n",
    "                body_crop = image[breast_y-h_size:breast_y+h_size, breast_x-w_size:breast_x+w_size, :]\n",
    "                body_crop = imresize(body_crop, size=(new_height, new_width))\n",
    "                print('body crop shape:', body_crop.shape)\n",
    "                print('bxmin:', bxmin, 'bxmax:', bxmax, 'bymin:', bymin, 'bymax:', bymax)\n",
    "                print('leg_y', leg_y, 'nape_y', nape_y)\n",
    "            # get crop for head\n",
    "            x_len = abs(beak_x - nape_x)\n",
    "            y_len = abs(crown_x - nape_x)\n",
    "            bymin, bymax = min(nape_y, crown_y), max(nape_y, crown_y) + y_len\n",
    "            bxmin, bxmax = max(crown_x - x_len, 0), min(crown_x + x_len, width)\n",
    "            bymin, bymax, bxmin, bxmax = int(bymin), int(bymax), int(bxmin), int(bxmax)\n",
    "            \n",
    "            try:\n",
    "                head_crop = image[bymin:bymax, bxmin:bxmax, :]\n",
    "                head_crop = imresize(head_crop, size=(new_height, new_width))\n",
    "            except:\n",
    "                h_size = int((0.3 * h) / 2)\n",
    "                w_size = int((0.3 * w) / 2)\n",
    "                \n",
    "                if crown_y == 0.0 or crown_x == 0.0:\n",
    "                    head_x, head_y = nape_x, nape_y\n",
    "                else:\n",
    "                    head_x, head_y = crown_x, crown_y\n",
    "                plt.imshow(image)\n",
    "                head_crop = image[head_y-h_size:head_y+h_size, head_x-w_size:head_x+w_size, :]\n",
    "\n",
    "                print('image shape:', image.shape)\n",
    "                print('head crop shape:', head_crop.shape)\n",
    "                print('new height:', new_height, 'new width:', new_width)\n",
    "                print('bxmin:', bxmin, 'bxmax:', bxmax, 'bymin:', bymin, 'bymax:', bymax)\n",
    "                print('crown_x:', crown_x, 'x_len:', x_len)\n",
    "\n",
    "            if mode == 'train':\n",
    "                # resize the image to 256xS where S is max(largest-image-side, 244)\n",
    "                # TODO: this seems semi random not sure why STN used this\n",
    "                clipped_height, clipped_width = max(height, 244), max(width, 244)\n",
    "                if height > width:\n",
    "                    image = imresize(image, size=(clipped_height, 256))\n",
    "                else:\n",
    "                    image = imresize(image, size=(256, clipped_width))\n",
    "                image = random_crop(image, new_height)\n",
    "                image = horizontal_flip(image)\n",
    "            else:\n",
    "                image = central_crop(image, central_fraction=0.875)\n",
    "                image = imresize(image, size=(new_height, new_width, new_channels))\n",
    "            image_and_parts = np.stack([image, body_crop, head_crop], axis=0)\n",
    "            return image_and_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished train\n",
      "finished test\n",
      "finished val\n",
      "('image shape:', (500, 333, 3))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-25ffee52e832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFewshotBirdsDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_episode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# see what the parts and images look like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-88daeaabf3a9>\u001b[0m in \u001b[0;36msample_episode_batch\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mepisodes_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mepisodes_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mepisodes_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_examples_for_image_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mepisodes_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepisodes_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepisodes_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-88daeaabf3a9>\u001b[0m in \u001b[0;36m_get_examples_for_image_configs\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mimage_and_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                         \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_and_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_and_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-88daeaabf3a9>\u001b[0m in \u001b[0;36m_parser\u001b[0;34m(self, image_path, size, bbox, parts_x, parts_y, mode)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mbody_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbreast_y\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbreast_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreast_x\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mw_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbreast_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mbody_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'body crop shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bxmin:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bxmax:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bymin:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bymax:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/anaconda2/envs/tensorflow/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \"\"\"\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/anaconda2/envs/tensorflow/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mtoimage\u001b[0;34m(arr, high, low, cmin, cmax, pal, mode, channel_axis)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# Here we know data and mode is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/anaconda2/envs/tensorflow/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2324\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/anaconda2/envs/tensorflow/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tile cannot extend outside image"
     ]
    }
   ],
   "source": [
    "\n",
    "data_generator = FewshotBirdsDataGenerator()\n",
    "xs, ys = data_generator.sample_episode_batch(data_generator.train_data)\n",
    "\n",
    "# see what the parts and images look like\n",
    "#f, ax = plt.subplots(data_generator.batch_size, 3, figsize=(3*3, data_generator.batch_size*3))\n",
    "'''\n",
    "for i in range(data_generator.batch_size):\n",
    "    ax[i, 0].imshow(xs[0][i, 0])\n",
    "    ax[i, 0].set_title('original')\n",
    "    ax[i, 1].imshow(xs[0][i, 1])\n",
    "    ax[i, 1].set_title('breast')\n",
    "    ax[i, 2].imshow(xs[0][i, 2])\n",
    "    ax[i, 2].set_title('head')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def _parser(self, image_path, size, bbox, parts_x, parts_y, mode='test'):\n",
    "            # decode the image\n",
    "            image_file = tf.read_file(image_path) # imread(image_path)\n",
    "            image = tf.image.decode_jpeg(image_file, channels=self.image_dim[-1])\n",
    "            # get height and width of image to normalize the bounding box and part locations\n",
    "            height, width = size\n",
    "            # normalize bbox\n",
    "            x, y, w, h = bbox\n",
    "            # normalize parts\n",
    "            parts_x = [max(px / width, 0) for px in parts_x]\n",
    "            parts_y = [max(py / height, 0) for py in parts_y]\n",
    "            # extract parts\n",
    "            breast_x, breast_y = parts_x[3], parts_y[3]\n",
    "            crown_x, crown_y = parts_x[4], parts_y[4]\n",
    "            nape_x, nape_y = parts_x[9], parts_y[9]\n",
    "            tail_x, tail_y = parts_x[13], parts_y[13]\n",
    "            leg_x, leg_y = parts_x[7], parts_y[7]\n",
    "            beak_x, beak_y = parts_x[1], parts_y[1]\n",
    "\n",
    "            new_height, new_width, new_channels = self.image_dim\n",
    "            # get crop for body\n",
    "            bxmin, bxmax = tf.minimum(tail_x, beak_x), tf.maximum(tail_x, beak_x)\n",
    "            bymin, bymax = tf.minimum(leg_y, nape_y), tf.maximum(leg_y, nape_y)\n",
    "            boxes = tf.expand_dims(tf.stack([bymin, bxmin, bymax, bxmax], axis=0), 0)\n",
    "            box_ind = tf.constant([0])\n",
    "            # imresize, \n",
    "            body_crop = tf.image.crop_and_resize(tf.expand_dims(image, 0), boxes, box_ind, [new_height, new_width], method='bilinear', extrapolation_value=0, name=None)\n",
    "            body_crop = tf.squeeze(body_crop, [0])\n",
    "\n",
    "            # get crop for head\n",
    "            x_len = tf.abs(beak_x - nape_x)\n",
    "            y_len = tf.abs(crown_x - nape_x)\n",
    "            bymin, bymax = tf.minimum(nape_y, crown_y), tf.maximum(nape_y, crown_y) + y_len\n",
    "            bxmin, bxmax = crown_x - x_len, crown_x + x_len\n",
    "            boxes = tf.expand_dims(tf.stack([bymin, bxmin, bymax, bxmax], axis=0), 0)\n",
    "            head_crop = tf.image.crop_and_resize(tf.expand_dims(image, 0), boxes, box_ind, [new_height, new_width], method='bilinear', extrapolation_value=0, name=None)\n",
    "            head_crop = tf.squeeze(head_crop, [0])\n",
    "\n",
    "            if mode == 'train':\n",
    "                # resize the image to 256xS where S is max(largest-image-side, 244)\n",
    "                image = tf.expand_dims(image, 0)\n",
    "                clipped_height, clipped_width = max(height, 244), max(width, 244)\n",
    "                if height > width:\n",
    "                    image = tf.image.resize_bilinear(image, [clipped_height, 256], align_corners=False)\n",
    "                else:\n",
    "                    image = tf.image.resize_bilinear(image, [256, clipped_width], align_corners=False)\n",
    "                # TODO: get rid of this\n",
    "                #image = tf.image.resize_bilinear(image, [new_height, new_width], align_corners=False)\n",
    "                # TODO: ^\n",
    "                image = tf.squeeze(image, [0])\n",
    "                # preprocess with random crops and horizontal flipping\n",
    "                image = tf.random_crop(image, size=[new_height, new_width, new_channels])\n",
    "                image = tf.image.random_flip_left_right(image)\n",
    "            else:\n",
    "                image = tf.image.central_crop(image, central_fraction=0.875)\n",
    "                image = tf.expand_dims(image, 0)\n",
    "                image = tf.image.resize_bilinear(image, [new_height, new_width])\n",
    "                image = tf.squeeze(image, [0])\n",
    "                image = tf.cast(image, tf.uint8)\n",
    "                session = tf.Session()\n",
    "                plt.imshow(session.run(image))\n",
    "            image_and_parts = [image, body_crop, head_crop]\n",
    "            return image_and_parts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
